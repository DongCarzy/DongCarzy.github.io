<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[问题列表]]></title>
    <url>%2F2018%2F11%2F19%2Fjava%2Fproblem%2F</url>
    <content type="text"><![CDATA[问题列表 平时工作中遇到的问题以及解决办法 计算时差问题 静态Map，Set用作存储并发 获取 spring.profile.active 用户 计算时差问题StopWatch 类提供计时器 12345678910//获取并启动StopWatch sw = StopWatch.createStarted(); = &gt;StopWatch sw = new StopWatch();sw.start();//获取时间sw.getTime();orsw.getTime(TimeUnit.MINUTES); //TimeUnit表示不同时间形式 静态Map，Set用作存储并发采用 ConcurrentHashMap 替 HashMap类似 ConcurrentSkipListSet 替换 HashSet 12Map map = new ConcurrentHashMap();Set&lt;String&gt; set = new ConcurrentSkipListSet&lt;&gt;(); ConcurrentHashMap代码中可以看出，它引入了一个“分段锁”的概念，具体可以理解为把一个大的Map拆分成N个小的HashTable，根据key.hashCode()来决定把key放到哪个HashTable中。 在ConcurrentHashMap中，就是把Map分成了N个Segment，put和get的时候，都是现根据key.hashCode()算出放到哪个Segment中。 获取 spring.profile.active 用户]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2F2018%2F11%2F19%2Fjava%2Fdesign-pattern%2F</url>
    <content type="text"><![CDATA[设计模式设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。 什么是GOF(四人帮，全拼 Gang of Four)？ 对接口编程而不是对实现编程。 优先使用对象组合而不是继承。 最佳的实践设计模式已经经历了很长一段时间的发展，它们提供了软件开发过程中面临的一般问题的最佳解决方案。学习这些模式有助于经验不足的开发人员通过一种简单快捷的方式来学习软件设计。 设计模式的类型 23中设计模式 3大类 (创建型模式, 结构型模式, 行为型模式) 创建型模式 这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活 工厂模式 抽象工厂模式 单例模式 建造者模式 原型模式 结构型模式 这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式 适配器模式 桥接模式 过滤器模式 组合模式 装饰器模式 外观模式 享元模式 代理模式 行为型模式 关注对象之间的通信 责任模式 命令模式 解释器模式 迭代器模式 中介模式 备忘录模式 观察者模式 状态模式 空对象模式 策略模式 模板模式 访问者模式 J2EE模式(补充) 特别关注表示层,由 sun Java Center 鉴定 MVC模式 业务代码模式 组合实体模式 数据访问对象模式 前端控制器模式 拦截过滤器模式 服务定位模式 传输对象模式]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异常]]></title>
    <url>%2F2018%2F11%2F19%2Fjava%2Fexception%2F</url>
    <content type="text"><![CDATA[异常http://blog.csdn.net/mccand1234/article/details/51579425]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-cloud-gateway]]></title>
    <url>%2F2018%2F11%2F19%2Fspringboot%2Fspring-cloud-gateway%2F</url>
    <content type="text"><![CDATA[spring-cloud-gateway Route Predicate Filter How it Works 客户端向SpringCloudGateway提出请求。如果Gateway Handler映射确定请求与路由匹配，则将其发送到Gateway Web Handler。此处理程序通过特定于请求的筛选链发送请求。过滤器被虚线除以的原因是，过滤器可以在发送代理请求之前或之后执行逻辑。执行所有“预”筛选逻辑，然后发出代理请求。在发出代理请求后，执行“POST”筛选逻辑。]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot 默认配置项]]></title>
    <url>%2F2018%2F11%2F19%2Fspringboot%2Fboot-default-config%2F</url>
    <content type="text"><![CDATA[spring boot 默认配置项COMMON SPRING BOOT PROPERTIESThis sample file is provided as a guideline. Do NOT copy it in itsentirety to your own application. CORE PROPERTIES SPRING CONFIG (ConfigFileApplicationListener)spring.config.name= # config file name (default to ‘application’)spring.config.location= # location of config file PROFILESspring.profiles= # comma list of active profiles APPLICATION SETTINGS (SpringApplication)spring.main.sources=spring.main.web-environment= # detect by defaultspring.main.show-banner=truespring.main….= # see class for all properties LOGGINGlogging.path=/var/logslogging.file=myapp.loglogging.config= IDENTITY (ContextIdApplicationContextInitializer)spring.application.name=spring.application.index= EMBEDDED SERVER CONFIGURATION (ServerProperties)server.port=8080server.address= # bind to a specific NICserver.session-timeout= # session timeout in secondsserver.context-path= # the context path, defaults to ‘/‘server.servlet-path= # the servlet path, defaults to ‘/‘server.tomcat.access-log-pattern= # log pattern of the access logserver.tomcat.access-log-enabled=false # is access logging enabledserver.tomcat.protocol-header=x-forwarded-proto # ssl forward headersserver.tomcat.remote-ip-header=x-forwarded-forserver.tomcat.basedir=/tmp # base dir (usually not needed, defaults to tmp)server.tomcat.background-processor-delay=30; # in secondsserver.tomcat.max-threads = 0 # number of threads in protocol handlerserver.tomcat.uri-encoding = UTF-8 # character encoding to use for URL decoding SPRING MVC (HttpMapperProperties)http.mappers.json-pretty-print=false # pretty print JSONhttp.mappers.json-sort-keys=false # sort keysspring.mvc.locale= # set fixed locale, e.g. en_UKspring.mvc.date-format= # set fixed date format, e.g. dd/MM/yyyyspring.mvc.message-codes-resolver-format= # PREFIX_ERROR_CODE / POSTFIX_ERROR_CODEspring.view.prefix= # MVC view prefixspring.view.suffix= # … and suffixspring.resources.cache-period= # cache timeouts in headers sent to browserspring.resources.add-mappings=true # if default mappings should be added THYMELEAF (ThymeleafAutoConfiguration)spring.thymeleaf.prefix=classpath:/templates/spring.thymeleaf.suffix=.htmlspring.thymeleaf.mode=HTML5spring.thymeleaf.encoding=UTF-8spring.thymeleaf.content-type=text/html # ;charset=&lt;encoding&gt; is addedspring.thymeleaf.cache=true # set to false for hot refresh FREEMARKER (FreeMarkerAutoConfiguration)spring.freemarker.allowRequestOverride=falsespring.freemarker.allowSessionOverride=falsespring.freemarker.cache=truespring.freemarker.checkTemplateLocation=truespring.freemarker.contentType=text/htmlspring.freemarker.exposeRequestAttributes=falsespring.freemarker.exposeSessionAttributes=falsespring.freemarker.exposeSpringMacroHelpers=falsespring.freemarker.prefix=spring.freemarker.requestContextAttribute=spring.freemarker.settings.*=spring.freemarker.suffix=.ftlspring.freemarker.templateEncoding=UTF-8spring.freemarker.templateLoaderPath=classpath:/templates/spring.freemarker.viewNames= # whitelist of view names that can be resolved GROOVY TEMPLATES (GroovyTemplateAutoConfiguration)spring.groovy.template.allowRequestOverride=falsespring.groovy.template.allowSessionOverride=falsespring.groovy.template.cache=truespring.groovy.template.configuration.*= # See Groovy’s TemplateConfigurationspring.groovy.template.contentType=text/htmlspring.groovy.template.prefix=classpath:/templates/spring.groovy.template.suffix=.tplspring.groovy.template.templateEncoding=UTF-8spring.groovy.template.viewNames= # whitelist of view names that can be resolved VELOCITY TEMPLATES (VelocityAutoConfiguration)spring.velocity.allowRequestOverride=falsespring.velocity.allowSessionOverride=falsespring.velocity.cache=truespring.velocity.checkTemplateLocation=truespring.velocity.contentType=text/htmlspring.velocity.dateToolAttribute=spring.velocity.exposeRequestAttributes=falsespring.velocity.exposeSessionAttributes=falsespring.velocity.exposeSpringMacroHelpers=falsespring.velocity.numberToolAttribute=spring.velocity.prefix=spring.velocity.properties.*=spring.velocity.requestContextAttribute=spring.velocity.resourceLoaderPath=classpath:/templates/spring.velocity.suffix=.vmspring.velocity.templateEncoding=UTF-8spring.velocity.viewNames= # whitelist of view names that can be resolved INTERNATIONALIZATION (MessageSourceAutoConfiguration)spring.messages.basename=messagesspring.messages.cacheSeconds=-1spring.messages.encoding=UTF-8 SECURITY (SecurityProperties)security.user.name=user # login usernamesecurity.user.password= # login passwordsecurity.user.role=USER # role assigned to the usersecurity.require-ssl=false # advanced settings …security.enable-csrf=falsesecurity.basic.enabled=truesecurity.basic.realm=Springsecurity.basic.path= # /**security.headers.xss=falsesecurity.headers.cache=falsesecurity.headers.frame=falsesecurity.headers.contentType=falsesecurity.headers.hsts=all # none / domain / allsecurity.sessions=stateless # always / never / if_required / statelesssecurity.ignored=false DATASOURCE (DataSourceAutoConfiguration &amp; DataSourceProperties)spring.datasource.name= # name of the data sourcespring.datasource.initialize=true # populate using data.sqlspring.datasource.schema= # a schema (DDL) script resource referencespring.datasource.data= # a data (DML) script resource referencespring.datasource.platform= # the platform to use in the schema resource (schema-${platform}.sql)spring.datasource.continueOnError=false # continue even if can’t be initializedspring.datasource.separator=; # statement separator in SQL initialization scriptsspring.datasource.driverClassName= # JDBC Settings…spring.datasource.url=spring.datasource.username=spring.datasource.password=spring.datasource.max-active=100 # Advanced configuration…spring.datasource.max-idle=8spring.datasource.min-idle=8spring.datasource.initial-size=10spring.datasource.validation-query=spring.datasource.test-on-borrow=falsespring.datasource.test-on-return=falsespring.datasource.test-while-idle=spring.datasource.time-between-eviction-runs-millis=spring.datasource.min-evictable-idle-time-millis=spring.datasource.max-wait-millis= MONGODB (MongoProperties)spring.data.mongodb.host= # the db hostspring.data.mongodb.port=27017 # the connection port (defaults to 27107)spring.data.mongodb.uri=mongodb://localhost/test # connection URLspring.data.mongo.repositories.enabled=true # if spring data repository support is enabled JPA (JpaBaseConfiguration, HibernateJpaAutoConfiguration)spring.jpa.properties.*= # properties to set on the JPA connectionspring.jpa.openInView=truespring.jpa.show-sql=truespring.jpa.database-platform=spring.jpa.database=spring.jpa.generate-ddl=false # ignored by Hibernate, might be useful for other vendorsspring.jpa.hibernate.naming-strategy= # naming classnamespring.jpa.hibernate.ddl-auto= # defaults to create-drop for embedded dbsspring.data.jpa.repositories.enabled=true # if spring data repository support is enabled SOLR (SolrProperties})spring.data.solr.host=http://127.0.0.1:8983/solrspring.data.solr.zkHost=spring.data.solr.repositories.enabled=true # if spring data repository support is enabled ELASTICSEARCH (ElasticsearchProperties})spring.data.elasticsearch.cluster-name= # The cluster name (defaults to elasticsearch)spring.data.elasticsearch.cluster-nodes= # The address(es) of the server node (comma-separated; if not specified starts a client node)spring.data.elasticsearch.local=true # if local mode should be used with client nodesspring.data.elasticsearch.repositories.enabled=true # if spring data repository support is enabled FLYWAY (FlywayProperties)flyway.locations=classpath:db/migrations # locations of migrations scriptsflyway.schemas= # schemas to updateflyway.initVersion= 1 # version to start migrationflyway.prefix=Vflyway.suffix=.sqlflyway.enabled=trueflyway.url= # JDBC url if you want Flyway to create its own DataSourceflyway.user= # JDBC username if you want Flyway to create its own DataSourceflyway.password= # JDBC password if you want Flyway to create its own DataSource LIQUIBASE (LiquibaseProperties)liquibase.change-log=classpath:/db/changelog/db.changelog-master.yamlliquibase.contexts= # runtime contexts to useliquibase.default-schema= # default database schema to useliquibase.drop-first=falseliquibase.enabled=true JMXspring.jmx.enabled=true # Expose MBeans from Spring RABBIT (RabbitProperties)spring.rabbitmq.host= # connection hostspring.rabbitmq.port= # connection portspring.rabbitmq.addresses= # connection addresses (e.g. myhost:9999,otherhost:1111)spring.rabbitmq.username= # login userspring.rabbitmq.password= # login passwordspring.rabbitmq.virtualhost=spring.rabbitmq.dynamic= REDIS (RedisProperties)spring.redis.host=localhost # server hostspring.redis.password= # server passwordspring.redis.port=6379 # connection portspring.redis.pool.max-idle=8 # pool settings …spring.redis.pool.min-idle=0spring.redis.pool.max-active=8spring.redis.pool.max-wait=-1 ACTIVEMQ (ActiveMQProperties)spring.activemq.broker-url=tcp://localhost:61616 # connection URLspring.activemq.user=spring.activemq.password=spring.activemq.in-memory=true # broker kind to create if no broker-url is specifiedspring.activemq.pooled=false HornetQ (HornetQProperties)spring.hornetq.mode= # connection mode (native, embedded)spring.hornetq.host=localhost # hornetQ host (native mode)spring.hornetq.port=5445 # hornetQ port (native mode)spring.hornetq.embedded.enabled=true # if the embedded server is enabled (needs hornetq-jms-server.jar)spring.hornetq.embedded.serverId= # auto-generated id of the embedded server (integer)spring.hornetq.embedded.persistent=false # message persistencespring.hornetq.embedded.data-directory= # location of data content (when persistence is enabled)spring.hornetq.embedded.queues= # comma separate queues to create on startupspring.hornetq.embedded.topics= # comma separate topics to create on startupspring.hornetq.embedded.cluster-password= # customer password (randomly generated by default) JMS (JmsProperties)spring.jms.pub-sub-domain= # false for queue (default), true for topic SPRING BATCH (BatchDatabaseInitializer)spring.batch.job.names=job1,job2spring.batch.job.enabled=truespring.batch.initializer.enabled=truespring.batch.schema= # batch schema to load AOPspring.aop.auto=spring.aop.proxy-target-class= FILE ENCODING (FileEncodingApplicationListener)spring.mandatory-file-encoding=false SPRING SOCIAL (SocialWebAutoConfiguration)spring.social.auto-connection-views=true # Set to true for default connection views or false if you provide your own SPRING SOCIAL FACEBOOK (FacebookAutoConfiguration)spring.social.facebook.app-id= # your application’s Facebook App IDspring.social.facebook.app-secret= # your application’s Facebook App Secret SPRING SOCIAL LINKEDIN (LinkedInAutoConfiguration)spring.social.linkedin.app-id= # your application’s LinkedIn App IDspring.social.linkedin.app-secret= # your application’s LinkedIn App Secret SPRING SOCIAL TWITTER (TwitterAutoConfiguration)spring.social.twitter.app-id= # your application’s Twitter App IDspring.social.twitter.app-secret= # your application’s Twitter App Secret SPRING MOBILE SITE PREFERENCE (SitePreferenceAutoConfiguration)spring.mobile.sitepreference.enabled=true # enabled by default SPRING MOBILE DEVICE VIEWS (DeviceDelegatingViewResolverAutoConfiguration)spring.mobile.devicedelegatingviewresolver.enabled=true # disabled by defaultspring.mobile.devicedelegatingviewresolver.normalPrefix=spring.mobile.devicedelegatingviewresolver.normalSuffix=spring.mobile.devicedelegatingviewresolver.mobilePrefix=mobile/spring.mobile.devicedelegatingviewresolver.mobileSuffix=spring.mobile.devicedelegatingviewresolver.tabletPrefix=tablet/spring.mobile.devicedelegatingviewresolver.tabletSuffix= ACTUATOR PROPERTIES MANAGEMENT HTTP SERVER (ManagementServerProperties)management.port= # defaults to ‘server.port’management.address= # bind to a specific NICmanagement.contextPath= # default to ‘/‘ ENDPOINTS (AbstractEndpoint subclasses)endpoints.autoconfig.id=autoconfigendpoints.autoconfig.sensitive=trueendpoints.autoconfig.enabled=trueendpoints.beans.id=beansendpoints.beans.sensitive=trueendpoints.beans.enabled=trueendpoints.configprops.id=configpropsendpoints.configprops.sensitive=trueendpoints.configprops.enabled=trueendpoints.configprops.keys-to-sanitize=password,secretendpoints.dump.id=dumpendpoints.dump.sensitive=trueendpoints.dump.enabled=trueendpoints.env.id=envendpoints.env.sensitive=trueendpoints.env.enabled=trueendpoints.health.id=healthendpoints.health.sensitive=falseendpoints.health.enabled=trueendpoints.info.id=infoendpoints.info.sensitive=falseendpoints.info.enabled=trueendpoints.metrics.id=metricsendpoints.metrics.sensitive=trueendpoints.metrics.enabled=trueendpoints.shutdown.id=shutdownendpoints.shutdown.sensitive=trueendpoints.shutdown.enabled=falseendpoints.trace.id=traceendpoints.trace.sensitive=trueendpoints.trace.enabled=true MVC ONLY ENDPOINTSendpoints.jolokia.path=jolokiaendpoints.jolokia.sensitive=trueendpoints.jolokia.enabled=true # when using Jolokiaendpoints.error.path=/error JMX ENDPOINT (EndpointMBeanExportProperties)endpoints.jmx.enabled=trueendpoints.jmx.domain= # the JMX domain, defaults to ‘org.springboot’endpoints.jmx.unique-names=falseendpoints.jmx.enabled=trueendpoints.jmx.staticNames= JOLOKIA (JolokiaProperties)jolokia.config.*= # See Jolokia manual REMOTE SHELLshell.auth=simple # jaas, key, simple, springshell.command-refresh-interval=-1shell.command-path-pattern= # classpath:/commands/**, classpath:/crash/commands/*shell.config-path-patterns= # classpath:/crash/*shell.disabled-plugins=false # don’t expose pluginsshell.ssh.enabled= # ssh settings …shell.ssh.keyPath=shell.ssh.port=shell.telnet.enabled= # telnet settings …shell.telnet.port=shell.auth.jaas.domain= # authentication settings …shell.auth.key.path=shell.auth.simple.user.name=shell.auth.simple.user.password=shell.auth.spring.roles= GIT INFOspring.git.properties= # resource ref to generated git info properties file]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-session]]></title>
    <url>%2F2018%2F11%2F19%2Fspringboot%2Fspring-session%2F</url>
    <content type="text"><![CDATA[spring-sessionSpring Session提供了用于管理用户会话信息的API和实现。 特征spring session 使得支持集群会话变得很容易,而不依赖任何特定的应用程序容器,并且还提供以下信息 HttpSession - 允许应用程序容器(Tomcat) 中的 HttpSession, 在RESTFUL模式中SpringSession允许在标头中提供SessionId WebSocket - 提供在接收WebSocket消息时保持HttpSession活动的能力 WebSession - 允许以与应用程序容器无关的方式替换SpringWebFlux的WebSession 结构 springSession core - 提供springSession功能的核心API springSession Data Redis - 提供由Redis和配置支持的SessionRepository和ReactiveSessionRepository - 实现 SpringSession JDBC - 提供由关系数据库和配置支持的 SessionRepository实现 Spring Session Hazelcast - 提供由Hazelcast和配置支持的 SessionRepository实现 Spring SessionSpring Session 中透明的继承了HttpSession, 我们可以简单粗暴的使用 SpringSession替换我们传统的HttpSession. SpringSession优势 方便做集群会话,儿不限制使用特定的应用容器 SpringSession 支持在单个浏览器实例中管理多个用户会话 在RESTFUL模式中SpringSession允许在标头中提供SessionId SpringSession继承 redis Pivotal Gemfire JDBC Mongo Hazelcast HttpSession with Redis这是一个简单的案例,具体配置可以参考官网, 一下是一个spring的配置类,主要做了两件事 12345678@EnableRedisHttpSession public class Config &#123; @Bean public LettuceConnectionFactory connectionFactory() &#123; return new LettuceConnectionFactory(); &#125;&#125; @EnableRedisHttpSession 创建一个名为springSessionRepositoryFilter的过滤器,负责替换HttpSession变为SpringSession的实现,并且启动Redis对 session管理的支持 创建RedisConnectionFactory,它负责将SpringSession连接到 Redis Server, 此时的配置采用的默认配置, 即localhost:6379. spring data redis 默认支持 Lettuce and Jedis等 Redis连接工具 HttpSession 是如何工作得SessionRepositoryRequestWrapper我们知道,我们在操作的HttpSession和HttpServletRequest是两个接口,也正是因为这样,出现了 SessionRepositoryRequestWrapper对象,它继承于HttpServletRequestWrapper, 并重写了 getSession方法 12345678910111213141516public class SessionRepositoryRequestWrapper extends HttpServletRequestWrapper &#123; public SessionRepositoryRequestWrapper(HttpServletRequest original) &#123; super(original); &#125; public HttpSession getSession() &#123; return getSession(true); &#125; public HttpSession getSession(boolean createNew) &#123; // create an HttpSession implementation from Spring Session &#125; // ... other methods delegate to the original HttpServletRequest ...&#125; 返回HttpSession都被覆盖了。所有其他方法都由HttpServletRequestWrapper并简单地将其委托给原来的HttpServletRequest执行。 SessionRepositoryFilter下面是部分的伪代码 123456789101112public class SessionRepositoryFilter implements Filter &#123; public doFilter(ServletRequest request, ServletResponse response, FilterChain chain) &#123; HttpServletRequest httpRequest = (HttpServletRequest) request; SessionRepositoryRequestWrapper customRequest = new SessionRepositoryRequestWrapper(httpRequest); chain.doFilter(customRequest, response, chain); &#125; // ...&#125; 通过SessionRepositoryFilter过滤器,在这里去替换 HttpServletRequest 为 SessionRepositoryRequestWrapper,注意的是, Spring Session的过滤器SessionRepositoryFilter必须放在与HttpSession 交互的任何东西前面.]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cloud]]></title>
    <url>%2F2018%2F11%2F19%2Fspringboot%2Fspring-cloud%2F</url>
    <content type="text"><![CDATA[spring cloud 分布式/版本化配置 服务注册和发现 选路 服务对服务呼叫 负载平衡 断路器 分布式消息传递 cloud文档 spring cloud config配置管理中心, 通过 spring.cloud.config.server.git.uri 来获取git服务上的配置文档,当然也可配置成本地获取.客户端通过HTTP可以获取对应的 配置资源 12345/&#123;application&#125;/&#123;profile&#125;[/&#123;label&#125;]/&#123;application&#125;-&#123;profile&#125;.yml/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.yml/&#123;application&#125;-&#123;profile&#125;.properties/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.properties 服务端配置123456spring: cloud: config: server: git: uri: https://github.com/spring-cloud-samples/config-repo 客户端配置客户端依赖 SpringCloud-config-Client这个jar, 如果你直接引入了 spring-cloud-starter-config 则不需要额外添加 jar bootstrap.properties 12# 指向服务端的配置中心spring.cloud.config.uri: http://myconfigserver.com]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[上传 Docker Image]]></title>
    <url>%2F2017%2F11%2F20%2Fdocker%2F%E4%B8%8A%E4%BC%A0image%2F</url>
    <content type="text"><![CDATA[上传 Docker Image 再传之前我们需要建立在自己的私有仓库，不然就上传到docker仓库中心了 自己server服务器地址myServer = localhost 下文中localhost`替换成自己的服务器地址即可 建立自己的docker仓库 这里我用的是 Nexus3,8001端口是提供给image上传下载用的 1docker run -d -p 8000:8081 -p 8001:8001 sonatype/nexus3 默认的仓库会将 资源放在 /var/lib/docker/,随着容器的删除数据也会消失，需要挂载，具体看镜像介绍 1https://hub.docker.com/r/sonatype/nexus3/ 登陆 8000 端口后，进入设置，建立自己的 docker仓库。Repository -&gt; repositories -&gt; Create repository -&gt; docker(hosted) name 随便， HTTP或者HTTPS，根具需求填写，我这里勾选HTTP，端口协商8001，与上面暴露出来的端口保持一致，直接save就行了 创建一个Dockerfile.用官网的demo创建一个空目录。将目录（cd）更改到新目录中，创建一个文件 Dockerfile(dockerfile编写可参考官方文档) 1234567891011121314# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD ["python", "app.py"] 创建应用体（dockerfile中提及的两个文件）requirements.txt和app.py，并把它们与同一文件夹中Dockerfile。 创建requirements.txt12FlaskRedis 创建app.py123456789101112131415161718192021222324from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host="redis", db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route("/")def hello(): try: visits = redis.incr("counter") except RedisError: visits = "&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;" html = "&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;" \ "&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;" \ "&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;" return html.format(name=os.getenv("NAME", "world"), hostname=socket.gethostname(), visits=visits)if __name__ == "__main__": app.run(host='0.0.0.0', port=80) 构建image1docker build -t friendlyhello . -t 为你镜像打repository，默认tag为latest(friendlyhello:latest), . 表示存储位置的路径，具体的可以看 docker build –help. 通过 docker images 就可以看到刚刚的镜像了 登陆自己的仓库1234dokcer login -u $&#123;name&#125; -p $&#123;passwd&#125; $&#123;server地址&#125;我的是docker login -u admin -p admin123 $&#123;myServer&#125;:8001eg: docker login -u admin -p admin123 localhost:8001 如果登陆失败，则你需要将你得server地址加入 daemon 文档（即配置镜像加速的位置）， (vi /etc/docker/daemon.json)，比如 docker for windows, 右键右下角docker，选择settting-&gt;daemon -&gt; Insercure registries 配置上你服务器的地址加端口即可。（Registry mirrors 就是你配置镜像加速的位置了） make tag给镜像打上tag， docker tag –help 可查看详细用法 123格式 : docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG] docker tag image username/repository:tagdocker tag friendlyhello:latest localhost:8001/test:1.2docker push localhost:8001/test:1.2 至此，登录你的nexus3,在docker仓库就可以看见一个名字为 test,版本为1.2的镜像了 检查执行 docker search localhost/test:1.2 看是否存在删除本地已经存在的镜像 docker rmi localhost/test:1.2执行 docker run -d -p 8888:80 localhost/test:1.2, 可观察到下载的状况浏览器 访问 8888端口]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfiles的最佳实践]]></title>
    <url>%2F2017%2F11%2F16%2Fdocker%2FmakeDockerfile%2F</url>
    <content type="text"><![CDATA[编写Dockerfiles的最佳做法Docker可以通过从Dockerfile包含所有命令的文本文件中读取指令来自动构建图像 ，以便构建给定图像所需的顺序。 一般准则和建议容器应该是精简的使用.dockerignore文件在大多数情况下，最好将每个Dockerfile放在一个空目录中。然后，仅添加构建Dockerfile所需的文件。为了增加构建的性能，您可以通过.dockerignore向该目录添加文件来排除文件和目录。此文件支持类似于.gitignore文件的排除模式。 避免安装不必要的包为了减少复杂性，依赖性，文件大小和构建时间，您应该避免安装额外的或不必要的包 容器单纯化将应用程序分解成多个容器可以更轻松地水平扩展和重新使用容器。例如，Web应用程序堆栈可能由三个独立的容器组成，每个容器具有自己独特的映像，以解耦的方式管理Web应用程序，数据库和内存中缓存。尽可能地判断容器是否干净，模块化。如果容器相互依赖，则可以使用Docker容器网络 来确保这些容器可以通信。 最小化层数你需要找到dockerfile 可用性(长期可维护性)之间的平衡,并最大限度地减少其使用的层数。 排序多行参数只要有可能，通过以字母数字排序多行参数来缓解以后的更改。这将帮助您避免重复的包，并使列表更容易更新。这也使得PR更容易阅读和审查。在反斜杠（\）之前添加一个空格。 123456RUN apt-get update &amp;&amp; apt-get install -y \ bzr \ cvs \ git \ mercurial \ subversion 构建缓存在构建映像的过程中，Docker将Dockerfile按照指定的顺序逐步执行每个指令。随着每条指令的检查，Docker将在其缓存中查找可以重用的现有映像，而不是创建一个新的（重复）映像。用--no-cache=true该docker build命令上,将不会使用缓存何时会找到匹配的image 从已经在缓存中的父图像开始，将下一条指令与从该基础图像导出的所有子图像进行比较，以查看其中一个是否使用完全相同的指令构建。如果没有，则缓存无效。 在大多数情况下，简单地比较Dockerfile与其中一个子图像的指令是足够的。但是，某些说明需要更多的检查和解释。 对于ADD和COPY指令，检查图像中文件的内容，并为每个文件计算校验和。在这些校验和中不考虑文件的最后修改和最后访问的时间。在缓存查找期间，将校验和与现有映像中的校验和进行比较。如果文件（如内容和元数据）中有任何变化，则缓存无效。 除了ADD和COPY命令之外，缓存检查不会查看容器中的文件来确定缓存匹配。例如，当处理RUN apt-get -y update命令时，将不会检查在容器中更新的文件以确定是否存在高速缓存命中。在这种情况下，只有命令字符串本身将用于查找匹配。 一旦缓存无效，所有后续Dockerfile命令将生成新的映像，并且高速缓存将不被使用。 Dockerfile指令[x] FROM[x] LABEL[x] RUN[x] APT-GET[x] USING PIPES[x] CMD[x] EXPOSE[x] ENV[x] ADD or COPY[x] ENTRYPOINT[x] VOLUME[x] USER[x] WORKDIR[x] ONBUILD FROM只要有可能，使用现有的官方存储库作为您的图像的基础。 LABEL您可以为图像添加标签,(空格), &quot; 等字符需要转义 1234567891011121314# Set one or more individual labelsLABEL com.example.version="0.0.1-beta"LABEL vendor="ACME Incorporated"LABEL com.example.release-date="2015-02-12"LABEL com.example.version.is-production=""# Set multiple labels on one lineLABEL com.example.version="0.0.1-beta" com.example.release-date="2015-02-12"# Set multiple labels at once, using line-continuation characters to break long linesLABEL vendor=ACME\ Incorporated \ com.example.is-beta= \ com.example.is-production="" \ com.example.version="0.0.1-beta" \ com.example.release-date="2015-02-12" RUN为了使您Dockerfile更易于阅读，可理解和可维护，可以将RUN多个行分隔开，用反斜杠分隔的长整型或复杂语句。 APT-GET可能最常见的用例RUN是应用程序apt-get。该 RUN apt-get命令用来安装软件包避免，RUN apt-get upgrade或者dist-upgrade父系image中的许多“必需”程序包将无法在非特权的容器内升级 1234RUN apt-get update &amp;&amp; apt-get install -y \ package-bar \ package-baz \ package-foo apt-get update在RUN语句中单独使用会导致缓存问题和后续apt-get install指令失败,例如: 123FROM ubuntu:14.04RUN apt-get updateRUN apt-get install -y curl 构建图像后，所有层都在Docker缓存中。假设你以后apt-get install通过添加额外的包来修改： 123FROM ubuntu:14.04RUN apt-get updateRUN apt-get install -y curl nginx Docker将初始化和修改的指令看作是相同的，并重用先前步骤中的缓存。结果apt-get update是不执行，因为构建使用缓存的版本。因为apt-get update没有运行，你的构建可能会有一个过时的版本curl和nginx 包。使用RUN apt-get update &amp;&amp; apt-get install -y确保您的Docker文件安装最新的软件包版本，无需进一步的编码或手动干预。这种技术被称为“缓存破坏”。您还可以通过指定软件包版本来实现缓存清除。这被称为版本固定，版本固定强制构建以检索特定版本，而不管缓存中有什么。这种技术还可以减少由于所需软件包中意外的更改导致的故障。例如： 1234RUN apt-get update &amp;&amp; apt-get install -y \ package-bar \ package-baz \ package-foo=1.3.* 下是一个格式正确的RUN指导，显示所有apt-get 1234567891011121314RUN apt-get update &amp;&amp; apt-get install -y \ aufs-tools \ automake \ build-essential \ curl \ dpkg-sig \ libcap-dev \ libsqlite3-dev \ mercurial \ reprepro \ ruby1.9.1 \ ruby1.9.1-dev \ s3cmd=1.1.* \ &amp;&amp; rm -rf /var/lib/apt/lists/* USING PIPES一些RUN命令取决于使用管道字符（|）将一个命令的输出管道传输到另一个命令的能力 1RUN wget -O - https://some.site | wc -l &gt; /number Docker使用/bin/sh -c解释器执行这些命令，该解释器仅评估管道中最后一个操作的退出代码以确定成功。在上面的示例中，只要wc -l命令成功，即使wget命令失败，此构建步骤也可以成功并生成新映像。 您希望命令由于管道中任何阶段的错误而失败，请先set -o pipefail &amp;&amp;确定一个意外的错误会阻止构建从无意中成功。 1RUN set -o pipefail &amp;&amp; wget -O - https://some.site | wc -l &gt; /number 注意：并非所有的shell都支持该-o pipefail选项。在这种情况下（例如dash shell，它是基于Debian的映像的默认shell），请考虑使用exec形式RUN来显式选择一个支持该pipefail选项的shell 。 1RUN ["/bin/bash", "-c", "set -o pipefail &amp;&amp; wget -O - https://some.site | wc -l &gt; /number"] CMDCMD指令应用于运行图像包含的软件以及任何参数。如果图像用于服务，例如Apache和Rails，则可以运行类似的操作CMD [&quot;apache2&quot;,&quot;-DFOREGROUND&quot;]。这种形式的指令是推荐用于任何基于服务的图像。CMD应该给出一个交互式的shell，比如bash，python和perl。例如，CMD [&quot;perl&quot;, &quot;-de0&quot;]，CMD [&quot;python&quot;]，或 CMD [“php”, “-a”]。使用此表单意味着当您执行类似的操作时docker run -it python，您将被放入可用的shell中，随时可以使用。 EXPOSEEXPOSE指令指示容器将侦听连接的端口.例如，包含Apache Web服务器EXPOSE 80的映像将使用，而包含MongoDB的映像将使用EXPOSE 27017等等 ENV为了使新的软件更容易运行，您可以使用它ENV来更新PATH容器安装的软件的 环境变量。例如，ENV PATH /usr/local/nginx/bin:$PATH将确保CMD [“nginx”] 只是工作。该ENV指令对于提供特定于要集中化的服务的必需环境变量也很有用，例如Postgres’s PGDATA。最后，ENV也可以用来设置常用的版本号，使得版本颠覆更容易维 1234ENV PG_MAJOR 9.3ENV PG_VERSION 9.3.4RUN curl -SL http://example.com/postgres-$PG_VERSION.tar.xz | tar -xJC /usr/src/postgress &amp;&amp; …ENV PATH /usr/local/postgres-$PG_MAJOR/bin:$PATH ADD or COPYADD 和 COPY 的功能有点类似,但是一般优先采用COPY, 因为它更加透明.COPY只支持将本地文件基本复制到容器中，同时ADD具有一些不是立即显而易见的功能（如本地仅提取和远程URL支持）。因此，最好的用途ADD是将本地tar文件自动提取到图像中，如同 ADD rootfs.tar.xz /。因为图像大小很重要，ADD因此强烈不鼓励使用远程URL提取包; 你应该使用curl或wget替代。这样，您可以删除在解压后不再需要的文件，而不必在图像中添加另一个图层. 错误实例123ADD http://example.com/big.tar.xz /usr/src/things/RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/thingsRUN make -C /usr/src/things all 正确实例1234RUN mkdir -p /usr/src/things \ &amp;&amp; curl -SL http://example.com/big.tar.xz \ | tar -xJC /usr/src/things \ &amp;&amp; make -C /usr/src/things all ENTRYPOINTVOLUME该VOLUME指令应用于公开您的docker容器创建的任何数据库存储区域，配置存储或文件/文件夹。强烈建议您使用图像VOLUME的任何可变和/或用户可维修的部分。 USERWORKDIR为了清晰可靠，您应该永远为您使用绝对路径 WORKDIR。此外，您应该使用，WORKDIR而不是增加的说明，如RUN cd … &amp;&amp; do-something难以阅读，排除故障和维护 ONBUILDONBUILD命令在当前Dockerfile构建完成后执行。 ONBUILD在导出FROM当前图像的任何子图像中执行。将该ONBUILD命令视为父母Dockerfile给予孩子的指示Dockerfile。Docker构建ONBUILD在子节点Dockerfile中的任何命令之前执行命令。放入ADD或COPY放入时要小心ONBUILD。如果新版本的上下文缺少添加的资源，“onbuild”映像将会严重失败。如上所述，添加单独的标签将有助于通过允许Dockerfile作者做出选择来缓解这一点]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Swarm]]></title>
    <url>%2F2017%2F11%2F14%2Fdocker%2FDocker%20Swarm%2F</url>
    <content type="text"><![CDATA[Docker Swarm A swarm is a group of machines that are running Docker and joined into a cluster. After that has happened, you continue to run the Docker commands you’re used to, but now they are executed on a cluster by a swarm manager. The machines in a swarm can be physical or virtual. After joining a swarm, they are referred to as nodes. Swarm是什么 通过把多个Docker Engine聚集在一起，形成一个大的docker-engine，对外提供容器的集群服务。同时这个集群对外提供Swarm API，用户可以像使用Docker Engine一样使用Docker集群。 Swarm 特点 对外以Docker API接口呈现，这样带来的好处是，如果现有系统使用Docker Engine，则可以平滑将Docker Engine切到Swarm上，无需改动现有系统。 Swarm对用户来说，之前使用Docker的经验可以继承过来。非常容易上手，学习成本和二次开发成本都比较低。同时Swarm本身专注于Docker集群管理，非常轻量，占用资源也非常少。 Batteries included but swappable，简单说，就是插件化机制，Swarm中的各个模块都抽象出了API，可以根据自己一些特点进行定制实现。 Swarm自身对Docker命令参数支持的比较完善，Swarm目前与Docker是同步发布的。Docker的新功能，都会第一时间在Swarm中体现。 Swarm框架结构 Swarm对外提供两种API， 一种是Docker API，用于负责容器镜像的生命周期管理， 另外一种是Swarm集群管理CLI，用于集群理。 Scheduler模块，主要实现调度功能。在通过Swarm创建容器时，会经过Scheduler模块选择出一个最优节点，里面包含了两个子模块，分别是Filter和Strategy， Filter用来过滤节点，找出满足条件的节点（比如资源足够，节点正常等等），Strategy用来在过滤出的节点中根据策略选择一个最优的节点（比如对找出的节点进行对比，找到资源最多的节点等等）, 当然Filter/Strategy用户可以定制。 Swarm对集群进行了抽象，抽象出了Cluster API，Swarm支持两种集群，一种是Swarm自身的集群，另外一种基于Mesos的集群。 LeaderShip模块用于Swarm Manager自身的HA，通过主备方式实现。 Discovery Service 服务发现模块，这个模块主要用来提供节点发现功能。 在每一个节点上，都会有一个Agent，用于连接Discovery Service，上报Docker Daemon的IP端口信息，Swarm Manager会直接从服务发现模块中读取节点信息。 创建群集 (docker for windows) 本案例用的是 win10 的 hyper-V 功能mac,linux,windows7/8 参考官网: https://docs.docker.com/get-started/part4/#understanding-swarm-clusters 利用 hyper-v 在你的机器上创建两个docker 环境 启用 Hyper-V 管理器 点击虚拟交换机管理,创建一个 外部 类型的虚拟交换机 给你的虚拟交换机取名 myswitch create a couple of VMs using our node management tool,docker-machine 发现下载 boot2docker.iso 失败或者超时, 可到这个地址下载 https://github.com/boot2docker/boot2docker/releases/download/v17.06.2-ce/boot2docker.iso 然后将它放在你的 个人资源管理器 \.docker\machine\cache, 例如我的: C:\Users\carzy\.docker\machine\cache 123docker-machine create -d hyperv --hyperv-virtual-switch "myswitch" myvm1docker-machine create -d hyperv --hyperv-virtual-switch "myswitch" myvm2# 此过程很慢 查看刚刚创建的虚拟docker列表和IP1234docker-machine ls `NAME ACTIVE DRIVER STATE URL SWARM DOCKERmyvm1 - hyperv Running tcp://192.168.68.116:2376 v17.06.2-cemyvm2 - hyperv Running tcp://192.168.68.114:2376 v17.06.2-ce 启动群集添加节点 第一台机器将作为 manager ，执行管理指令和认证人员加入群，和第二将作为 worker docker-machine ssh 登录你的第一个 VM, 并将 myvm1 指定为 manager : docker swarm init 12345678910docker-machine ssh myvm1 "docker swarm init --advertise-addr &lt;myvm1 ip&gt;"docker@myvm1:~$ docker swarm initSwarm initialized: current node (pdi85vh4w3p5243qgiiaoz6cn) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-3r3xispwm7cbu0k8orry0k9dyn7if9agk2gkwrxilefrh5jfmu-3qzklzdzedh5yxinsi9q77xqt 192.168.68.116:2377To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. 端口2377和2376始终运行 docker swarm init和 docker swarm join 端口2377（群组管理端口），或使其为默认值。返回的机器IP地址 docker-machine ls 包括端口2376，它是Docker守护程序端口。不要使用这个端口，否则 可能会遇&gt; 到错误。 响应 docker swarm init包含预先配置的 docker swarm join命令(上条docker swarm init 提示的 token)，以便您在要添加的任何节点上运行。复制此命令，并将其发送到myvm2, docker-machine ssh 让myvm2 加入您的新群组作为worker 123docker swarm join --token SWMTKN-1-3r3xispwm7cbu0k8orry0k9dyn7if9agk2gkwrxilefrh5jfmu-3qzklzdzedh5yxinsi9q77xqt 192.168.68.116:2377This node joined a swarm as a worker. docker node ls 在管理器上运行以查看此群组中的节点 1234PS E:\dockerWork\demo1&gt; docker-machine ssh myvm1 "docker node ls"ID HOSTNAME STATUS AVAILABILITY MANAGER STATUSpdi85vh4w3p5243qgiiaoz6cn * myvm1 Ready Active Leadertra1o8vdg9y4z16uv0nl731y8 myvm2 Ready Active 离开群如果要重新开始，可以从每个节点运行 docker swarm leave 部署应用将docker-machineshell 配置为群组管理器 到目前为止，已经将Docker的commmands包装在 docker-machine ssh与VM进行通话。另一个选项是运行 docker-machine env &lt;machine&gt; 以获取并运行一个配置当前shell的命令来与虚拟机上的 Docker守护程序 通信。它允许使用本地docker-compose.yml文件“远程”部署应用程序，而无需将其复制到任何位置。 Run docker-machine env myvm1 to get the command to configure your shell to talk to myvm1. Run the given command to configure your shell to talk to myvm1 Run docker-machine ls to verify that myvm1 is the active machine as indicated by * next to it 开始部署 现在你有我的myvm1，你可以使用myvm1 的权力作为一个群组管理器来部署您的应用程序，使用 docker stack deploy 命令，运行 docker-stack.yml. 1docker stack deploy -c docker-compose.yml test 检测 docker service ps test 可以看到5个容器，分别运行在 myvm1 和 myvm2 上 通过浏览器访问任意一个 ip 的，都可以看见 5 个 不同的 ID IP地址工作的原因是群集中的 nodes 加入 ingress network routing mesh 。这样可以确保在群集中某个端口部署的服务始终将该端口保留给其自身，无论实际运行的是哪个节点。以下是在三节点群集my-web端口8080上发布的服务的路由网格如何显示： 连通问题为了在群集中使用入口网络 ingress network ，在启用群组模式之前，需要在群集节点之间打开以下端口 端口7946 TCP / UDP用于容器网络发现。 端口4789 UDP用于容器入口网络. 迭代和缩放您的应用程序 通过更改docker-compose.yml文件来缩放应用程序 通过编辑代码来更改应用程序行为 在这两种情况下，只需 docker stack deploy 再次运行以部署这些更改. 您可以使用与 docker swarm join 您使用的相同的命令将任何物理或虚拟机加入此群集 myvm2 ，并将容量添加到群集中。docker stack deploy 运行后，您的应用程序将利用新的资源。 清理使用 docker stack rm 进行清理所有这个stack Keep the swarm or remove itdocker-machine ssh myvm2 &quot;docker swarm leave&quot; 将 myvm2 从swarm的 worker 中移除docker-machine ssh myvm1 &quot;docker swarm leave --force myvm1 从 swarm的 manager 中移除]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker stack]]></title>
    <url>%2F2017%2F11%2F14%2Fdocker%2Fdocker%20stack%2F</url>
    <content type="text"><![CDATA[docker stack 将到达分布式应用程序层次结构的顶部：堆栈。堆栈是一组相互关联的服务，共享依赖关系，并且可以协调一致。单个堆栈能够定义和协调整个应用程序的功能（尽管非常复杂的应用程序可能希望使用多个堆栈）。 添加新服务并重新部署很容易为我们的docker-compose.yml文件添加服务。首先，我们添加一个免费的可视化服务，让我们看看我们的群集如何调度容器。 docker-compose.yml 在编辑器中打开并将其内容替换为以下内容。请务必更换 username/repo:tag 您的图像细节。 123456789101112131415161718192021222324252627282930version: "3"services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: "0.1" memory: 50M ports: - "80:80" networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - "8080:8080" volumes: - "/var/run/docker.sock:/var/run/docker.sock" deploy: placement: constraints: [node.role == manager] networks: - webnetnetworks: webnet: 这里唯一新的是对等服务web，命名visualizer。您将在这里看到两个新的东西：一个volumes关键字，让可视化程序访问Docker的主机套接字文件以及一个placement关键字，确保这个服务只能运行在群组管理器上，而不是工作人员。这是因为由Docker创建的开源项目构建的这个容器显示了在图中以群集运行的Docker服务。 确保你的shell被配置为通话myvm1（全部的例子在这里）。 运行docker-machine ls列出机器，并确保您已连接到myvm1，如下星号所示。 如果需要，重新运行docker-machine env myvm1，然后运行给定的命令配置shell。 在Mac或Linux上，命令是：eval $(docker-machine env myvm1) 在Windows上，命令是：&amp; &quot;C:\Program Files\Docker\Docker\Resources\bin\docker-machine.exe&quot; env myvm1 | Invoke-Expression docker stack deploy在管理员上重新运行命令，任何需要更新的服务将被更新： 123$ docker stack deploy -c docker-compose.yml getstartedlabUpdating service getstartedlab_web (id: angi1bf5e4to03qu9f93trnxm)Updating service getstartedlab_visualizer (id: l9mnwkeq2jiononb5ihz9u7a4) 看看可视化器。 您在Compose文件中看到在visualizer端口8080上运行docker-machine ls。通过运行获取其中一个节点的IP地址。转到8080端口的IP地址，您将看到可视化运行： 单个副本visualizer正如您所期望的那样在管理器上运行，并且5个实例web分布在群集中。您可以通过运行docker stack ps &lt;stack&gt;以下方式来证实这种可视化: 1docker stack ps getstartedlab 可视化器是一种独立的服务，可以在包含在堆栈中的任何应用程序中运行。它不依赖于其他任何东西。现在让我们创建一个确实具有依赖性的服务：Redis服务将提供一个访客计数器。 数据让我们再次浏览相同的工作流程，添加一个用于存储应用数据的Redis数据库。 保存这个新docker-compose.yml文件，最后添加一个Redis服务。请务必更换username/repo:tag您的图像细节。 123456789101112131415161718192021222324252627282930313233343536373839404142version: "3"services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: "0.1" memory: 50M ports: - "80:80" networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - "8080:8080" volumes: - "/var/run/docker.sock:/var/run/docker.sock" deploy: placement: constraints: [node.role == manager] networks: - webnet redis: image: redis ports: - "6379:6379" volumes: - /home/docker/data:/data deploy: placement: constraints: [node.role == manager] command: redis-server --appendonly yes networks: - webnetnetworks: webnet: Redis在Docker图书馆有一个官方形象，并且被赋予了简短的image名字redis，所以username/repo在这里没有符号。Redis端口6379已由Redis预配置为从容器暴露给主机，在我们的撰写文件中，我们将其从主机公开到世界各地，因此您可以输入任何您的IP地址节点进入Redis Desktop Manager并管理此Redis实例，如果您这样选择。 最重要的是，在redis规范中有几件事情使数据在这个堆栈的部署之间保持不变： redis 总是在经理上运行，所以它总是使用相同的文件系统。 redis访问主机文件系统中的任意目录/data，这是Redis存储数据的位置。 在一起，这是在您的主机的物理文件系统中为Redis数据创建“真相的根源”。没有这个，Redis会将其数据存储 /data在容器的文件系统内，如果容器被重新部署，那么它将被清除。 这个真理的来源有两个部分： 您放置在Redis服务上的放置约束，确保它始终使用相同的主机。 您创建的卷允许容器访问./data（在主机上）为/data（在Redis容器内）。当容器来回走动时，存储在./data指定主机上的文件将持续存在，从而实现连续性。 您已准备好部署新的Redis使用堆栈。 ./data 在管理器上创建一个目录： 1docker-machine ssh myvm1 "mkdir ./data" 确保你的shell被配置为通话myvm1。 运行docker-machine ls列出机器，并确保您已连接到myvm1，如下星号所示。 如果需要，重新运行docker-machine env myvm1，然后运行给定的命令配置shell。 在Mac或Linux上，命令是：eval $(docker-machine env myvm1)在Windows上，命令是：&amp; &quot;C:\Program Files\Docker\Docker\Resources\bin\docker-machine.exe&quot; env myvm1 | Invoke-Expression 再运行docker stack deploy一次 1docker stack deploy -c docker-compose.yml getstartedlab 运行docker service ls以验证三个服务是否按预期运行。 12345$ docker service lsID NAME MODE REPLICAS IMAGE PORTSx7uij6xb4foj getstartedlab_redis replicated 1/1 redis:latest *:6379-&gt;6379/tcpn5rvhm52ykq7 getstartedlab_visualizer replicated 1/1 dockersamples/visualizer:stable *:8080-&gt;8080/tcpmifd433bti1d getstartedlab_web replicated 5/5 orangesnap/getstarted:latest *:80-&gt;80/tcp 检查您的一个节点（例如http://192.168.99.101）的网页，您将看到访客计数器的结果，该计数器现在已存在，并存储有关Redis的信息。 另外，检查可视化在上的任一节点的IP地址端口8080，你会看到redis与一起运行服务web和visualizer服务。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker serveice]]></title>
    <url>%2F2017%2F11%2F12%2Fdocker%2Fdocker%20serveice%2F</url>
    <content type="text"><![CDATA[docker serveice 扩展了应用程序并启用了负载平衡。 分布式应用程序的层次结构 Stack 堆 services 服务 container 什么事 serveice在分布式应用程序中，应用程序的不同部分称为“服务”。例如，如果您想像一个视频共享站点，它可能包括一个用于在数据库中存储应用程序数据的服务，一个在后台进行视频转码的服务用户上传东西，前端服务等等。服务只是“生产中的容器”。一个服务只运行一个映像，但它编码映像运行的方式 - 应该使用哪些端口，容器应容器，集装箱该运行多少副本，以便服务具有所需的容量，以及等等。扩展服务会更改运行该软件的容器实例的数量，并在该过程中为服务分配更多的计算资源。 docker-compose.yml编写一个docker-compose.yml文件是一个YAML文件，它定义了Docker容器在生产过程中的行为。 12345678910111213141516171819version: "3"services: web:# 将 60.205.206.164:8001/test:1.2 替换成你的 image ~~REPOSITORY：TAG~~ image: 60.205.206.164:8001/test:1.2 deploy: replicas: 5 resources: limits: cpus: "0.1" memory: 50M restart_policy: condition: on-failure ports: - "8090:80" networks: - webnetnetworks: webnet: Docker执行以下操作 从仓库中拉取 60.205.206.164:8001/test:1.2 这个 image 运行该映像的5个实例作为调用的服务web，限制每个实例使用，最多使用10％的CPU（跨所有内核）和50MB RAM 将主机上的端口8090映射到web80端口 指示web容器通过称为负载平衡网络共享端口8090 webnet。（在内部，集装箱本身将web端口发布到 80端口。） webnet使用默认设置（这是一个负载平衡的覆盖网络）来定义网络。 运行新的负载均衡应用 初始化swarm : docker swarm init 给应用取一个名字： docker stack deploy -c docker-compose.yml getstartedlab 通过 docker service ls 可以看到 我们的单一服务堆栈在一个主机上运行我们部署映像的5个容器实例。通过 docker service ps &lt;serviceId&gt; 可以看到这个服务包含了5个容器，都有独立的 ID 页面运行 8090 端口，不断的运行，会发现走了不通的容器 Hostname 显示的ID 一直在变化 缩放应用 更改docker-compose.yml的replicas值，保存更改并重新运行docker stack deploy命令来缩放应用程 通过 docker service ps &lt;serviceId&gt; 可以看到这个服务包含容器的个数变化 Take down the app and the swarm docker stack rm getstartedlab This removes the app, but our one-node swarm is still up and running docker swarm leave --force Take down the swarm]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门]]></title>
    <url>%2F2017%2F11%2F11%2Fdocker%2FDocker%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Docker入门搜索docker镜像1docker search tutorial 下载容器 可能可能需要配置镜像加速 1docker pull learn/tutorial docker容器可以理解为在沙盒中运行的进程。这个沙盒包含了该进程运行所必须的资源，包括文件系统、系统类库、shell 环境等等。但这个沙盒默认是不会运行任何程序的。你需要在沙盒中运行一个进程来启动某一个容器。这个进程是该容器的唯一进程，所以当该进程结束的时候，容器也会完全的停止。 在容器中安装新的程序tutorial镜像是基于ubuntu的，所以你可以使用ubuntu的apt-get命令来安装ping程序：apt-get install -y ping。 1docker run learn/tutorial apt-get install -y ping 保存对容器的修改当你对某一个容器做了修改之后（通过在容器中运行某一个命令），可以把对容器的修改保存下来，这样下次可以从保存后的最新状态运行该容器。docker中保存状态的过程称之为committing，它保存的新旧状态之间的区别，从而产生一个新的版本 运行docker commit，可以查看该命令的参数列表。 你需要指定要提交保存容器的ID。(译者按：通过docker ps -l 命令获得) 无需拷贝完整的id，通常来讲最开始的三至四个字母即可区分。（译者按：非常类似git里面的版本号) 1docker commit 698 learn/ping 运行新的镜像在新的镜像中运行 ping www.baidu.com 命令 1docker run lean/ping ping www.baidu.com 发布docker镜像我们可以将其发布到官方的索引网站。还记得我们最开始下载的learn/tutorial镜像吧，我们也可以把我们自己编译的镜像发布到索引页面，一方面可以自己重用，另一方面也可以分享给其他人使用 配置镜像加速 国内做Docker镜像站的还蛮多的，阿里、163、DaoCloud这些都是比较好的镜像站地址 比如win10 上 Docker for Windows 阿里的镜像站地址为：https://dev.aliyun.com/search.html ，访问该地址然后登陆阿里云账号—-&gt;在产品控制台—&gt;Docker镜像仓库 –&gt;镜像库—&gt;Docker Hub 镜像站点 Copy “您的专属加速器地址” 右键电脑右下角的Docker 图标–&gt;Settings–&gt;Daemon—&gt; 将加速器地址复制到该页面上的文本框中，点击Apply 然后等待Docker重启，重启完毕就可以使用新的Docker镜像源了 其余几个机器的配置方式在参考 阿里云 https://dev.aliyun.com/search.html]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker安装]]></title>
    <url>%2F2017%2F11%2F10%2Fdocker%2FDocker%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Docker安装Ubuntu 14.04 16.04 (使用apt-get进行安装) Step 1: 安装必要的一些系统工具 123sudo apt-get updatesudo apt-get -y install apt-transport-https ca-certificatescurl software-properties-common Step 2: 安装GPG证书 1curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - Step 3: 写入软件源信息 1sudo add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable" Step 4: 更新并安装Docker-CE 12sudo apt-get -y updatesudo apt-get -y install docker-ce 安装指定版本的Docker-CE: Step 1: 查找Docker-CE的版本: 12apt-cache madison docker-ce # docker-ce | 17.03.1~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packagesdocker-ce | 17.03.0~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages Step 2: 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.1~ce-0~ubuntu-xenial) 1sudo apt-get -y install docker-ce=[VERSION] Step 3: 安装最新版本的Docker-CE: 1sudo apt-get -y install docker-ce CentOS 7 (使用yum进行安装) step 1: 安装必要的一些系统工具 1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 Step 2: 添加软件源信息 1sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo Step 3: 更新并安装 Docker-CE 12sudo yum makecache fastsudo yum -y install docker-ce Step 4: 开启Docker服务 1sudo service docker start 安装指定版本的Docker-CE Step 1: 查找Docker-CE的版本 1234567yum list docker-ce.x86_64 --showduplicates | sort -rLoading mirror speeds from cached hostfileLoaded plugins: branch, fastestmirror, langpacksdocker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.03.1.ce-1.el7.centos @docker-ce-stabledocker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stableAvailable Packages Step2 : 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.0.ce.1-1.el7.centos) 1sudo yum -y install docker-ce-[VERSION] 安装校验 查看docker信息 1docker version 运行一个简单的 docker image。 会输出一个 hello world! 1docker run 'hello-world']]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker简述]]></title>
    <url>%2F2017%2F10%2F09%2Fdocker%2Fdocker%E7%AE%80%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[docker简述VM &amp; Docker 一般都拿VM与docker做比较，但两者的两个不同的东西，从使用者的角度上看，感觉是一样 docker VM docker engine Docker守护进程Docker守护程序（dockerd）监听Docker API请求并管理Docker对象，如图像，容器，网络和卷。守护进程还可以与其他守护进程通信以管理Docker服务 Docker客户端Docker client（docker）是许多Docker用户与Docker进行交互的主要方式。当您使用诸如docker run客户端之类的命令时dockerd，会发送这些命令。该docker命令使用Docker API。Docker客户端可以与多个守护进程通信。 Docker对象当您使用Docker时，您正在创建和使用图像，容器，网络，卷，插件和其他对象。本节简要介绍一些这些对象。 image一个图像是一个只读用于创建一个泊坞容器的指令模板。通常，图像是基于另一个图像，还有一些额外的定制.要创建自己的映像，您将创建一个 具有简单语法的Docker文件，用于定义创建映像所需的步骤并运行它。Dockerfile中的每条指令在图像中创建一个图层。当您更改Dockerfile并重建图像时，只有那些已更改的图层被重建。 集装箱容器是图像的可运行实例。您可以使用Docker API或CLI创建，运行，停止，移动或删除容器。您可以将容器连接到一个或多个网络，将存储器连接到该网络，或者甚至根据其当前状态创建新映像。默认情况下，容器与其他容器及其主机相对较好地隔离。您可以控制容器的网络，存储或其他底层子系统与其他容器或主机之间的隔离。容器由其图像定义，以及您在创建或运行时提供的任何配置选项。当一个容器被移除时，对其中不存储在永久存储器中的状态的任何更改消失。 服务服务允许你扩展在多个码头工人守护进程，而这一切的共同努力容器群有多个经理和工人。群集的每个成员都是Docker守护进程，守护进程使用Docker API进行通信。服务允许您定义所需的状态，例如在任何给定时间必须可用的服务的副本数。默认情况下，服务在所有工作节点之间进行负载平衡。对消费者来说，Docker服务似乎是一个单一的应用程序。Docker Engine支持Docker 1.12及更高版本的群集模式。 命名空间Docker使用一种被称为namespaces提供称为容器的隔离工作空间的技术。运行容器时，Docker会为该容器创建一组 命名空间。这些命名空间提供了一个隔离层。容器的每个方面都在一个单独的命名空间中运行，其访问仅限于该命名空间。Docker Engine在Linux上使用以下命名空间： 的pid命名空间：进程隔离（PID：进程ID）。 该net命名空间：管理网络接口（NET：网络）。 该ipc命名空间：管理访问IPC资源（IPC：进程间通信）。 该mnt命名空间：管理文件系统挂载点（MNT：摩）。 该uts命名空间：隔离内核和版本标识符。（UTS：Unix分时系统）]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[锁表与解锁]]></title>
    <url>%2F2017%2F06%2F14%2FDB%2FDB%E9%94%81%2F</url>
    <content type="text"><![CDATA[锁表与解锁ORACLE查询锁表情况1234SELECT object_name, machine, s.sid, s.serial#FROM gv$locked_object l, dba_objects o, gv$session sWHERE l.object_id = o.object_idAND l.session_id = s.sid 锁表1LOCK TABLE CAM_ACCOUNT_MST IN SHARE MODE ; 解锁12alter system kill session 'sid, serial#'ALTER system kill session '17, 23019' 查询锁表情况212345678910111213SELECT l.session_id sid, s.serial#, l.locked_mode 锁模式, l.oracle_username 登录用户, l.os_user_name 登录机器用户名, s.machine 机器名, s.terminal 终端用户名, o.object_name 被锁对象名, s.logon_time 登录数据库时间FROM v$locked_object l, all_objects o, v$session sWHERE l.object_id = o.object_id AND l.session_id = s.sidORDER BY sid, s.serial#;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>锁表与解锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PL/SQL developer 12.0 注册码]]></title>
    <url>%2F2017%2F03%2F16%2FDB%2FPL_SQL%2F</url>
    <content type="text"><![CDATA[数据库工具PL/SQL developer 12.0 注册码 LicenseNumber : 999 productCode ： 46jvnzf74ysf3mqm4hx4tvhcamh8gpe3v5 SeriesNumber：706090 password：xs374ca]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>db</tag>
        <tag>数据库工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jedis config 配置说明]]></title>
    <url>%2F2016%2F12%2F14%2FDB%2Fredis-jedis%2F</url>
    <content type="text"><![CDATA[JEDIS-2.4.2jedis config 配置说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748JedisPoolConfig config = new JedisPoolConfig();//连接耗尽时是否阻塞, false报异常,ture阻塞直到超时, 默认trueconfig.setBlockWhenExhausted(true);//设置的逐出策略类名, 默认DefaultEvictionPolicy(当连接超过最大空闲时间,或连接数超过最大空闲连接数)config.setEvictionPolicyClassName("org.apache.commons.pool2.impl.DefaultEvictionPolicy");//是否启用pool的jmx管理功能, 默认trueconfig.setJmxEnabled(true);//MBean ObjectName = new ObjectName("org.apache.commons.pool2:type=GenericObjectPool,name=" + "pool" + i); 默认为"pool", JMX不熟,具体不知道是干啥的...默认就好.config.setJmxNamePrefix("pool");//是否启用后进先出, 默认trueconfig.setLifo(true);//最大空闲连接数, 默认8个config.setMaxIdle(8);//最大连接数, 默认8个config.setMaxTotal(8);//获取连接时的最大等待毫秒数(如果设置为阻塞时BlockWhenExhausted),如果超时就抛异常, 小于零:阻塞不确定的时间, 默认-1config.setMaxWaitMillis(-1);//逐出连接的最小空闲时间 默认1800000毫秒(30分钟)config.setMinEvictableIdleTimeMillis(1800000);//最小空闲连接数, 默认0config.setMinIdle(0);//每次逐出检查时 逐出的最大数目 如果为负数就是 : 1/abs(n), 默认3config.setNumTestsPerEvictionRun(3);//对象空闲多久后逐出, 当空闲时间&gt;该值 且 空闲连接&gt;最大空闲数 时直接逐出,不再根据MinEvictableIdleTimeMillis判断 (默认逐出策略) config.setSoftMinEvictableIdleTimeMillis(1800000);//在获取连接的时候检查有效性, 默认falseconfig.setTestOnBorrow(false);//在空闲时检查有效性, 默认falseconfig.setTestWhileIdle(false);//逐出扫描的时间间隔(毫秒) 如果为负数,则不运行逐出线程, 默认-1config.setTimeBetweenEvictionRunsMillis(-1);JedisPool pool = new JedisPool(config, "localhost");]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>jedis</tag>
        <tag>redis</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker创建数据库]]></title>
    <url>%2F2016%2F11%2F14%2FDB%2Fdocker_create_db%2F</url>
    <content type="text"><![CDATA[docker创建数据库mysql1docker run --name some-mysql -v /home/dxp/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:5.7]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
</search>
